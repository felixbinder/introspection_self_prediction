{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating meta level finetuning dataset config.\n"
     ]
    }
   ],
   "source": [
    "from evals.create_finetuning_dataset_configs import create_finetuning_dataset_config\n",
    "\n",
    "\n",
    "# yaml_path = create_finetuning_dataset_config(\n",
    "#     'baseline-test',\n",
    "#     'gpt-3.5-turbo',\n",
    "#     'wikipedia',\n",
    "#     'minimal',\n",
    "#     'identity',\n",
    "#     \"\",  # overrides string—not using that here\n",
    "#     \"exp/baseline-test/object_level_gpt-3.5-turbo-1106_object_level_minimal_prompt_wikipedia_train_task__note\",\n",
    "#     \"exp/baseline-test/object_level_gpt-3.5-turbo-1106_object_level_minimal_prompt_wikipedia_val_task__note\",\n",
    "#     overwrite=False,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "meta_yaml_path = create_finetuning_dataset_config(\n",
    "    'baseline-test',\n",
    "    'gpt-3.5-turbo',\n",
    "    'wikipedia',\n",
    "    'minimal',\n",
    "    'identity',\n",
    "    \"\",  # overrides string—not using that here\n",
    "    # \"exp/baseline-test/object_level_gpt-3.5-turbo-1106_object_level_minimal_prompt_wikipedia_train_task__note\",\n",
    "    \"exp/baseline-test/meta_level_gpt-3.5-turbo-1106_wikipedia_task_0_shot_True_seed_meta_level_minimal_prompt_identity_resp_train_task__note\",\n",
    "    \"exp/baseline-test/meta_level_gpt-3.5-turbo-1106_wikipedia_task_0_shot_True_seed_meta_level_minimal_prompt_identity_resp_val_task__note\",\n",
    "    # \"exp/baseline-test/object_level_gpt-3.5-turbo-1106_object_level_minimal_prompt_wikipedia_val_task__note\",\n",
    "    overwrite=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/exp/finetuning/baseline-test/gpt-3.5-turbo/gpt-3.5-turbo_wikipedia_identity_minimal.yaml')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "../exp/finetuning/training_on_everything_may_15_w_gemini/gpt-3.5-turbo/train_dataset-format_gemini-test.jsonl\n",
      "> \u001b[0;32m/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/evals/create_finetuning_dataset.py\u001b[0m(138)\u001b[0;36mcreate_gemini_dataset_version\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    137 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 138 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from evals.create_finetuning_dataset import create_gemini_dataset_version\n",
    "\n",
    "# /evals/create_finetuning_dataset.py\n",
    "create_gemini_dataset_version('../exp/finetuning/training_on_everything_may_15_w_gemini/gpt-3.5-turbo/train_dataset-format_openai.jsonl') # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"Previously, you were asked the following question: \\\"Please write a short story according to the following instructions: Write a story about a society that lives on massive, floating islands in the sky.\\nThe story should be three paragraphs long. Respond only with the story and nothing else.\\\" What is the first word of the response you gave? Respond only with that word.\\n\"}, {\"role\": \"assistant\", \"content\": \"In\"}], \"string\": \"Write a story about a society that lives on massive, floating islands in the sky.\"}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"Previously, you were asked the following question: \\\"You are giving advice to this person who has written to an advice column. Please provide a short paragraph of advice to the following issue: i'm 19 and i got married six months ago to the love of my life! we have a great relationship despite how young we are. there's one probl\n"
     ]
    }
   ],
   "source": [
    "# /scratch.ipynb\n",
    "# /Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/evals/\n",
    "with open('../exp/finetuning/training_on_everything_may_15_w_gemini/gpt-3.5-turbo/train_dataset-format_openai.jsonl', 'r') as f:\n",
    "    print(f.read()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/evals'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/exp/finetuning/training_on_everything_may_15_w_gemini/gpt-3.5-turbo/train_dataset-format_gemini.jsonl') as f:\n",
    "    data = f.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
