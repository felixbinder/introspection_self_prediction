{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random sequence dataset\n",
    "\n",
    "This notebook generates a .jsonl file for a dataset that consists of sequences of random items from a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a set of items\n",
    "that we can then use to generate sequences of items from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "# download corpus if necessary\n",
    "nltk.download(\"words\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SETS = {\n",
    "    \"numbers\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "    \"letters\": [\n",
    "        \"a\",\n",
    "        \"b\",\n",
    "        \"c\",\n",
    "        \"d\",\n",
    "        \"e\",\n",
    "        \"f\",\n",
    "        \"g\",\n",
    "        \"h\",\n",
    "        \"i\",\n",
    "        \"j\",\n",
    "        \"k\",\n",
    "        \"l\",\n",
    "        \"m\",\n",
    "        \"n\",\n",
    "        \"o\",\n",
    "        \"p\",\n",
    "        \"q\",\n",
    "        \"r\",\n",
    "        \"s\",\n",
    "        \"t\",\n",
    "        \"u\",\n",
    "        \"v\",\n",
    "        \"w\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "    ],\n",
    "    \"animals\": [\n",
    "        \"dog\",\n",
    "        \"cat\",\n",
    "        \"cow\",\n",
    "        \"horse\",\n",
    "        \"sheep\",\n",
    "        \"goat\",\n",
    "        \"chicken\",\n",
    "        \"pig\",\n",
    "        \"duck\",\n",
    "        \"rabbit\",\n",
    "        \"deer\",\n",
    "        \"elephant\",\n",
    "        \"lion\",\n",
    "        \"tiger\",\n",
    "        \"bear\",\n",
    "        \"giraffe\",\n",
    "        \"zebra\",\n",
    "        \"kangaroo\",\n",
    "        \"panda\",\n",
    "        \"wolf\",\n",
    "        \"fox\",\n",
    "        \"squirrel\",\n",
    "        \"mouse\",\n",
    "        \"rat\",\n",
    "        \"frog\",\n",
    "        \"turtle\",\n",
    "        \"snake\",\n",
    "        \"lizard\",\n",
    "        \"fish\",\n",
    "        \"shark\",\n",
    "    ],\n",
    "    \"english_words\": words.words(),\n",
    "    \"number_doublets\": [f\"{n:02d}\" for n in range(100)],\n",
    "    \"number_triplets\": [f\"{n:03d}\" for n in range(1000)],\n",
    "    \"number_quadruplets\": [f\"{n:04d}\" for n in range(10000)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which set of items to use?\n",
    "SET = \"number_triplets\"\n",
    "# how long should the strings be?\n",
    "STRING_LENGTHS = [7, 10]\n",
    "# how many strings should be generated?\n",
    "N = 10000 + 2500 # for 0.8/0.2 train/test split\n",
    "# how to join?\n",
    "JOIN_ON = \" \"\n",
    "# what should the output be called?\n",
    "NAME = SET\n",
    "# test/val split\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_strings(\n",
    "    string_set=\"numbers\", seed: int = 42, string_length: int | list[int] = [6, 10], num: int = 1000, join_on: str = \" \"\n",
    "):\n",
    "    random.seed(seed)\n",
    "    data = []\n",
    "    if isinstance(string_length, int):\n",
    "        string_length = [string_length, string_length]\n",
    "\n",
    "    if string_set not in RANDOM_SETS:\n",
    "        raise ValueError(f\"Set {string_set} not found in RANDOM_SETS\")\n",
    "\n",
    "    print(f\"Generating random strings from a set: {string_set}\")\n",
    "    strings = set()\n",
    "    for i in range(num):\n",
    "        k = random.randint(string_length[0], string_length[1])\n",
    "        string = join_on.join(random.choices(RANDOM_SETS[string_set], k=k)) + join_on\n",
    "        # check for uniqueness\n",
    "        if string in strings:\n",
    "            continue\n",
    "        strings.add(string)\n",
    "        data.append({\"id\": i, \"string\": string})\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_random_strings(string_set=SET, string_length=STRING_LENGTHS, num=N, join_on=JOIN_ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to file and split into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strings_to_jsonl(df, filename: Path):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f'{{\"string\": \"{row[\"string\"]}\"}}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.locations import DATASET_DIR\n",
    "filepath = DATASET_DIR / f\"{NAME}.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "write_strings_to_jsonl(df, filepath.with_name(f\"all_{NAME}.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and train\n",
    "val_df = df.sample(frac=VAL_SPLIT, random_state=42)\n",
    "train_df = df.drop(val_df.index)\n",
    "\n",
    "# save to file\n",
    "write_strings_to_jsonl(train_df, filepath.with_name(f\"train_{NAME}.jsonl\"))\n",
    "write_strings_to_jsonl(val_df, filepath.with_name(f\"val_{NAME}.jsonl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
