response_property,accuracy,error,bootstrap_upper,bootstrap_lower,shifted,mode_baseline,compliance_rate,count,complied_count,object_model,meta_model,label
GPT-4o,0.3259455198856425,0.0033579511561267483,0.3292059102507581,0.322672103990488,0.0,0.32980642058434534,0.9757524748507074,74853,74853,gpt-4o-2024-05-13,gpt-4o-2024-05-13,1) Mft predicting Mft
GPT-4o,0.4940569649847033,0.0035809484356801313,0.5157331703472139,0.5085026652238387,0.0,0.2831950623221514,0.9937343860633508,74853,74853,ft:gpt-4o-2024-05-13:dcevals-kokotajlo::9oUVKrCU,ft:gpt-4o-2024-05-13:dcevals-kokotajlo::9oUVKrCU,2) Mft_shifted predicting Mft_shifted
Llama 70b,0.26416265903695135,0.0030152353052249614,0.2669781457356791,0.26128934071954707,0.0,0.3861325865952395,0.5616972058196871,82135,82135,llama-70b-fireworks,llama-70b-fireworks,1) Mft predicting Mft
Llama 70b,0.48507451147501063,0.00341854282858417,0.491545321726426,0.48489620746332257,0.0,0.36141717903451637,0.9745053874718451,82135,82135,llama-70b-14aug-20k-jinja,llama-70b-14aug-20k-jinja,2) Mft_shifted predicting Mft_shifted
GPT-3.5,0.16335768070165543,0.0027209501629135158,0.16615104768888012,0.16053681716912488,0.0,0.2772920838151104,0.9872951859894527,70918,70918,gpt-3.5-turbo-0125,gpt-3.5-turbo-0125,1) Mft predicting Mft
GPT-3.5,0.37312572200350586,0.0035970424050469907,0.37853135147561706,0.37134615937239573,0.0,0.2904250122129946,0.9810339377568321,69598,69598,ft:gpt-3.5-turbo-0125:dcevals-kokotajlo::9oDjQaY1,ft:gpt-3.5-turbo-0125:dcevals-kokotajlo::9oDjQaY1,2) Mft_shifted predicting Mft_shifted
